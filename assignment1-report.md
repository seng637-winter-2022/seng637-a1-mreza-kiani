>   **SENG 637- Dependability and Reliability of Software Systems**

**Lab. Report \#1 â€“ Introduction to Testing and Defect Tracking**

| Group \#: 16           |   
|------------------------|
| Shahryar Soltanpour    |
| Mohammad Reza Kianifar |
| Muhammad Raihan        |

**Table of Contents**
- [Introduction](#introduction)
- [Link of demo video](#link-of-demo-video)
- [High-level description of the exploratory testing plan](#high-level-description-of-the-exploratory-testing-plan)
- [Comparison of exploratory and manual functional testing](#comparison-of-exploratory-and-manual-functional-testing)
- [Notes and discussion of the peer reviews of defect reports](#notes-and-discussion-of-the-peer-reviews-of-defect-reports)
- [How the pair testing was managed and team work/effort was divided](#how-the-pair-testing-was-managed-and-team-workeffort-was-divided)
- [Difficulties encountered, challenges overcome, and lessons learned](#difficulties-encountered-challenges-overcome-and-lessons-learned)
- [Comments/feedback on the lab and lab document itself](#commentsfeedback-on-the-lab-and-lab-document-itself)


# Introduction

In this project, we have an ATM software executable file in two versions.

We started testing this software using exploratory testing method. In this mode of testing, you should be familiar with system functionality. Then we can specify a plan for manual exploring in the software and testing it and report bugs.

For the next step (manual scripted testing) we were given 40 test cases and we should run the test cases and to see if the software behaves as expected in the scripts. If not, we reported those test cases as bugs in Backlog. If the same bug was found during exploratory testing, we won't enter it again in Backlog. The first two steps were performed on ATM V1.0.

The next phase is regression testing. We used ATM V1.1 for this phase and checked whether the bugs are resolved in the new version or not and marked the resolved bugs as 'resolved' in Backlog.

Before this lab, we had the experience of writing automated tests for software coded by ourselves. But we didn't have much experience about writing plans for exploratory testing or performing tests based on given test case scenarios. 

# Link of demo video 

Make a video of the demo and put its link here.
All members must participate in the demo and the video should not be longer than 10 minutes.



# High-level description of the exploratory testing plan

Our exploratory testing plan for this system is to firstly, start by testing its main features. These features are namely Logging in, Withdrawal, Deposit, Cash Transfer and Balance Inquiry. We will test these features one by one to make sure they work as they should when the proper steps are followed. Afterwards, we will perform further testing by trying to "break" the system. To accomplish this, we will try inputting incorrect inputs at certain steps. For example, using the keys 5,6,7,8,9 or 0 on menus where an option for those keys isn't listed. 


# Comparison of exploratory and manual functional testing

We've found nine bugs during exploratory testing and eight more bugs in manual scripted testing (17 bugs in total). The report generated by Backlog.com is submitted as well.


- In exploratory testing, the tester should know the system well. but in manual scripted testing, the tester just goes step by step with the given scenario and the actual outcome is not expected, will report it. 
- Exploratory testing depends hugely on tester's creativity and may have a different result each time you perform the test. 
- It's more probable to find some exceptional paths in exploratory testing.
- It's much easier to convert manual scripted tests into automated tests.
- Manual scripted testing needs more documentation and needs a test case preparation phase before performing the test, while exploratory test does not. 

Knowing the points above, we believe that a combination of both these methods are required before releasing the software to ensure that we minimize the potential bugs.  
# Notes and discussion of the peer reviews of defect reports
We have done steps below for peer reviewing of defect reports: 

- After Muhammad has done the exploratory testing, Mohammad Reza examined bugs found by him again and checked if everything is working correctly or removing some of them if needed.
- After Mohammad Reza and Shahryar has checked their 20 test cases, they checked each other 20 use cases as well and fixed any probable mistakes in reporting bugs.
- After Mohammad Reza and Shahryar completed their work for 40 test cases, Muhammad has checked their work result to see if everything's okay.
- During the regression test, after each person check if his reported bugs are fixed in the new version, he checked other teammates reported bugs as well to double-check their work.

# How the pair testing was managed and team work/effort was divided 

First, Muhammad wrote his exploratory plan for testing and reported found bugs on Backlog. In the next phase, Mohammad Reza and Shahryar divided the 40 test cases between themselves (Mohammad Reza: 1-20 and Shahryar: 21-40) and reported new bugs. We also double-checked each other test cases to make sure nothing is missed. For the regression part, each one of us checked the bugs reported by himself to see whether it's resolved or not.

Each one of us answered one of the requested parts in the report, and we merged all of them inside one file and reviewed each other answers as well. 

# Difficulties encountered, challenges overcome, and lessons learned

Actually, we didn't face any major difficulties and almost everything went smoothly. Maybe if we weren't forced to have virtual meetings on Discord or attend the class on Zoom it would be much better experience to communicate with other groupmates, TA, and the professor. But I think we could manage virtual meetings by having regular meeting and responding message fast and on-time.  

# Comments/feedback on the lab and lab document itself

The assigment has been clearly defined what is required to do and what we should do for the report and demo. It also has a good definition of testing concepts and contains useful resources and links for more information about testing.

The work load of the assignment was reasonable as well, and we could manage to get it done in the expected time. We also became familiar with various types of manual testing.

It seems that some parts of the assignment description were outdated, for instance it says that we should have a demo in the lab session while we don't have lab session in this semester, and we should just upload the demo video.  
