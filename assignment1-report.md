> **SENG 637- Dependability and Reliability of Software Systems**

**Lab. Report \#1 – Introduction to Testing and Defect Tracking**

| Group \#:              | 16  |   
|------------------------|-----|
| Shahryar Soltanpour    |     |
| Mohammad Reza Kianifar |     |
| Muhammad Raihan        |     |

**Table of Contents**

- [Introduction](#introduction)
- [Link of demo video](#link-of-demo-video)
- [High-level description of the exploratory testing plan](#high-level-description-of-the-exploratory-testing-plan)
- [Comparison of exploratory and manual functional testing](#comparison-of-exploratory-and-manual-functional-testing)
- [Notes and discussion of the peer reviews of defect reports](#notes-and-discussion-of-the-peer-reviews-of-defect-reports)
- [How the pair testing was managed and team work/effort was divided](#how-the-pair-testing-was-managed-and-team-workeffort-was-divided)
- [Difficulties encountered, challenges overcome, and lessons learned](#difficulties-encountered-challenges-overcome-and-lessons-learned)
- [Comments/feedback on the lab and lab document itself](#commentsfeedback-on-the-lab-and-lab-document-itself)

# Introduction

In this project, we have an ATM software executable file in two versions, and we were assigned to test it with 3
different methods: exploratory testing, manual scripted testing, and regression testing.

We started testing this software using exploratory testing method. In this mode of testing, you should be familiar with
system functionality. Then we can specify a plan for manual exploring in the software and testing it and report bugs. In
this method, the tester could test small units of the program or its immense functionalities

For the next step (manual scripted testing) we were given 40 test cases and we should run the test cases and to see if
the software behaves as expected in the scripts. If not, we reported those test cases as bugs in Backlog. If the same
bug was found during exploratory testing, we won't enter it again in Backlog. The first two steps were performed on ATM
V1.0.

The next phase is regression testing. We used ATM V1.1 for this phase and checked whether the bugs are resolved in the
new version or not and marked the resolved bugs as 'resolved' in Backlog.

Before this lab, we had the experience of writing automated tests for software coded by ourselves. But we didn't have
much experience about writing plans for exploratory testing or performing tests based on given test case scenarios.

# Link of demo video

Make a video of the demo and put its link here. All members must participate in the demo and the video should not be
longer than 10 minutes.

# High-level description of the exploratory testing plan

Our plan’s first step was to understand what the application is and how it works. For this purpose, we read the system’s
requirements and try to work a little with the system to get familiar with it. Then we found out that it's better to
firstly start by testing its main features. These features are namely Logging in, Withdrawal, Deposit, Cash Transfer and
Balance Inquiry. We tested these features one by one extensively to make sure they work as they should when the proper 
steps are followed. Afterwards, we performed further testing by trying to "break" the system. To accomplish this, we 
tried inputting incorrect inputs at certain steps. For example, using the keys 5,6,7,8,9 or 0 on menus where an option 
for those keys isn't listed, or entering big values as input.

Any bugs that were found through this process, was listed on Backlog.

# Comparison of exploratory and manual functional testing

We've found nine bugs during exploratory testing and eight more bugs in manual scripted testing (17 bugs in total). The
Excel report generated by Backlog.com is submitted as well.

- In exploratory testing, the tester should know the system well. But in manual scripted testing, the tester just goes
  step by step with the given scenario and the actual outcome is not expected, will report it.
- Exploratory testing depends hugely on tester's creativity and may have a different result each time you perform the
  test.
- It's more probable to find some exceptional paths in exploratory testing.
- It's much easier to convert manual scripted tests into automated tests.
- Manual scripted testing needs more documentation and needs a test case preparation phase before performing the test,
  while exploratory test does not.
- With manual scripted testing you will explore all the use-cases and functionalities of the software, so you will find
  more bugs. But in exploratory testing you might miss some bugs because it's possible that you forget some paths
  through the program. So MST is more effective when we have a good documentation.
- In exploratory testing, because you will find the bugs without documentation, you have to spend more time for fining
  the same amount of bugs compared with MST. So exploratory testing is more time-consuming and is less efficient.
- In case of major issues, we can find them faster in exploratory testing, but there is no guarantee that we find all
  minor issues in this method.

Knowing the points above, we believe that a combination of both these methods are required before releasing the software
to ensure that we minimize the potential bugs.

# Notes and discussion of the peer reviews of defect reports

We have done steps below for peer reviewing of defect reports:

- After Muhammad has done the exploratory testing, Mohammad Reza examined bugs found by him again and checked if
  everything is working correctly or removing some of them if needed.
- After Mohammad Reza and Shahryar has checked their 20 test cases, they checked each other 20 use cases as well and
  fixed any probable mistakes in reporting bugs.
- After Mohammad Reza and Shahryar completed their work for 40 test cases, Muhammad has checked their work result to see
  if everything's okay.
- During the regression test, after each person check if his reported bugs are fixed in the new version, he checked
  other teammates reported bugs as well to double-check their work.

These are also some notes about the new version:

- In version 1.0, when the customer wants to deposit money, the ATM does not work correctly; for example, the customer
  deposits $20, and the ATM only adds $10 to his balance. However, in version 1.1, it adds $19.90 to the customer's
  balance. We consider it as a bug when we ran regression testing, since it was not mentioned anywhere that depositing
  money in the bank has a fee.
- In version 1.1, the withdrawing money worked find but there was a typo in menu of the available amounts. There is no $
  sign for third option, 60. But we didn't mention that because this typo was not available in version 1.0.
- Sometimes there was a main reason for a number of bugs. For instance because the amounts in withdraw menu were not
  working as they were supposed to, we faced some other bugs like withdrawing more money than your balance or what ATM
  has but since they were major bugs, we had to mention all of them in the issues report.

# How the pair testing was managed and team work/effort was divided

First, Muhammad wrote his exploratory plan for testing and reported found bugs on Backlog. Then Mohammad Reza
double-checked him and there were some modifications on the found bugs. In the next phase, Mohammad Reza and Shahryar
divided the 40 test cases between themselves (Mohammad Reza: 1-20 and Shahryar: 21-40) and reported new bugs. We also
double-checked each other test cases to make sure nothing is missed. For the regression part, each one of us checked the
bugs reported by himself to see whether it's resolved or not.

Each one of us answered one of the requested parts in the report, and we merged all of them inside one file and reviewed
each other answers as well.

# Difficulties encountered, challenges overcome, and lessons learned

Actually, we didn't face any major difficulties and almost everything went smoothly. Maybe if we weren't forced to have
virtual meetings on Discord or attend the class on Zoom it would be much better experience to communicate with other
groupmates, TA, and the professor in-person. But I think we could manage virtual meetings by having regular meeting and
responding message fast and on-time. 
We used Zoom as our communication platform. It supports both text messaging and voice/video chat.

# Comments/feedback on the lab and lab document itself

The assigment has been clearly defined what is required to do and what we should do for the report and demo. It also has
a good definition of testing concepts and contains useful resources and links for more information about testing.

The work load of the assignment was reasonable as well, and we could manage to get it done in the expected time. We also
became familiar with various types of manual testing.

It seems that some parts of the assignment description were outdated, for instance it says that we should have a demo in
the lab session while we don't have lab session in this semester, and we should just upload the demo video. Or it was
mentioned that there is a separated appendix A and B, but we could only find some tables at the end of the instruction
document. The TA answered our question quickly but nobody answered the forum. Because questions there were our questions
too and if professor or TA had answered that, we didn't bother them by asking them again through email. 
